 // Ollama API configuration
        const OLLAMA_BASE_URL = 'http://127.0.0.1:11434';
        const DEFAULT_MODEL = 'richardyoung/qwen3-14b-abliterated:latest'; // Change this to your preferred model

        // Ollama API helper functions
        async function callOllama(prompt, streaming = false) {
            try {
                const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: DEFAULT_MODEL,
                        prompt: prompt,
                        stream: streaming,
                        options: {
                            temperature: 0.7,
                            top_p: 0.9
                        }
                    })
                });

                if (!response.ok) {
                    throw new Error(`Ollama API error: ${response.status} ${response.statusText}`);
                }

                if (streaming) {
                    return response;
                } else {
                    const data = await response.json();
                    return data.response;
                }
            } catch (error) {
                console.error('Ollama API call failed:', error);
                throw error;
            }
        }

        async function callOllamaStreaming(prompt, onChunk, onComplete, onError) {
            try {
                const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: DEFAULT_MODEL,
                        prompt: prompt,
                        stream: true,
                        options: {
                            temperature: 0.7,
                            top_p: 0.9
                        }
                    })
                });

                if (!response.ok) {
                    throw new Error(`Ollama API error: ${response.status} ${response.statusText}`);
                }

                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let fullResponse = '';

                try {
                    while (true) {
                        const { done, value } = await reader.read();
                        if (done) break;

                        const chunk = decoder.decode(value);
                        const lines = chunk.split('\n').filter(line => line.trim());

                        for (const line of lines) {
                            try {
                                const data = JSON.parse(line);
                                if (data.response) {
                                    fullResponse += data.response;
                                    onChunk(fullResponse);
                                }
                                if (data.done) {
                                    onComplete(fullResponse);
                                    return;
                                }
                            } catch (e) {
                                // Ignore malformed JSON lines
                            }
                        }
                    }
                } finally {
                    reader.releaseLock();
                }
            } catch (error) {
                onError(error);
            }
        }
